---
title: "anes"
author: "Ryan Zhang"
date: "10/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Read relevant libraries.

library(tidyverse)
library(Hmisc)
library(rqPen)
library(vctrs)
library(foreign)
```


## Read Data

```{r warning=FALSE}
# Read in the raw data file, converting non-responses to NAs and only filtering
# for results before January 29, 2008 (since that is the date before Super
# Tuesday primaries).

naes04 <- read.spss("raw_data/naes/naes04-nh.sav", to.data.frame = TRUE,
                    use.value.labels = FALSE)
naes04[naes04 == 998] <- NA
naes04[naes04 == 999] <- NA
```


## Clean Data

```{r}
df04 <- naes04 %>%

  # Only select columns that correspond to the survey questions that I am
  # interested in, which includes question about favorability, viability,
  # electability, and ideology.
  
  select(cKEY, cRB06, 
         cAB01, cAC04,
         cNA05, cNA03,
         cNA21, cNA15,
         
         cMA06, 
         cAB27, cAC14
         )

# Rename columns.

my_candidate <- c("KERRY","EDWARDS")
my_candidate_id <- as.integer(c(5, 3))

my_names <- c("ID", "voting", 
              "Feeling1", "Feeling2", 
              "Viability1", "Viability2", 
              "Electability1", "Electability2",
              
              "Ideology", 
              "Ideology1", "Ideology2"
              )

# Replace numbered survey responses with words, for ease of readability.

colnames(df04) <- my_names
```


```{r}
df04$Viability1 <- ifelse(is.na(df04$Viability1), 100 - df04$Viability2,
                          df04$Viability1)
df04$Viability2 <- ifelse(is.na(df04$Viability2), 100 - df04$Viability1,
                          df04$Viability2)

df04$Electability1 <- ifelse(is.na(df04$Electability1), 100 -
                               df04$Electability2, df04$Electability1)
df04$Electability2 <- ifelse(is.na(df04$Electability2), 100 -
                               df04$Electability1, df04$Electability2)
```


```{r}
# Create a new columns that includes a column named VoteCandidate, which
# displays the respondent's ultimate primary pick. This column is needed, since
# it will be the dependent variable in my conditional logistic regression later.

df <- data.frame(my_candidate_id, my_candidate, stringsAsFactors = FALSE)
df04 <-merge(df04, df, by.x = "voting", by.y = "my_candidate_id", all.x = TRUE)
names(df04)[names(df04) == "my_candidate"] <- "VoteCandidate"

```


```{r eval=FALSE, include=FALSE}
# Verify that the column renaming, candidates, and their number 1-5 mapping are
# all correct.

str(df04)
```


## Clean Data (Part Two - Normalize Variables)

```{r warning=FALSE}
# 1. Build function that normalizes feeling thermometer ratings. 

my_rescale1 <- function(X) { 
  if (max(X, na.rm = TRUE) == min(X, na.rm = TRUE)) 
    X / sum(X, na.rm = TRUE)
  else
    round((X - min(X, na.rm = TRUE)) /
            (max(X, na.rm = TRUE) - min(X, na.rm = TRUE)), 6)
}

# Pass feeling thermometer columns (each representing the feeling thermometer
# rating for a different candidate) through the function.

df04[, c("NORMALIZED_FT1", "NORMALIZED_FT2")] <- t(apply(
  df04[, c("Feeling1", "Feeling2")], MARGIN = 1, FUN = my_rescale1))

# 2/3. Build function that normalizes viability and electability ratings. 

my_rescale2 <- function(X) round(X / sum(X, na.rm = TRUE), 6)

# Pass viability columns (each representing the viability rating for a different
# candidate) through the function.

df04[, c("NORMALIZED_VIABILITY1", "NORMALIZED_VIABILITY2")] <- t(apply(
  df04[, c("Viability1", "Viability2")], MARGIN = 1, FUN = my_rescale2))

# Pass electability columns (each representing the electability rating for a
# different candidate) through the function.

df04[, c("NORMALIZED_ELECTABILITY1", "NORMALIZED_ELECTABILITY2")] <- t(apply(
  df04[, c("Electability1", "Electability2")], MARGIN = 1, FUN = my_rescale2))

# 4. Calculate ideological distance. Each column represents the ideological
# rating for a different candidate.

df04[, c("temp_1", "temp_2")] <- square(
  df04[, c("Ideology1", "Ideology2")] - df04[, "Ideology"])

df04 <- df04 %>%
  rowwise() %>%
  mutate(temp_min = min(temp_1, temp_2)) %>%
  mutate(temp_max_min = max(temp_1, temp_2) - min(temp_1, temp_2)) %>%
  mutate(NORMALIZED_IDEOLOGY1 = ifelse(temp_max_min == 0,
                                       ifelse(temp_min == 0, 0, 0.5),
                                       round((temp_1 - temp_min) / 
                                               temp_max_min, 6))) %>%
  mutate(NORMALIZED_IDEOLOGY2 = ifelse(temp_max_min == 0,
                                       ifelse(temp_min == 0, 0, 0.5),
                                       round((temp_2 - temp_min) / 
                                               temp_max_min, 6))) %>%
  select(-starts_with("temp_") )

# Convert NANs to NAs, which will eventually be dropped. 

df04[df04 == "NaN"] <- NA
```
 
 
```{r}
# Verify my calculations, ensuring that all variables have been normalized
# correctly.

df04[, c("NORMALIZED_FT1", "NORMALIZED_FT2", "Feeling1", "Feeling2")]
df04[, c("NORMALIZED_VIABILITY1", "NORMALIZED_VIABILITY2", "Viability1", 
         "Viability2")]
df04[, c("NORMALIZED_ELECTABILITY1", "NORMALIZED_ELECTABILITY2", 
         "Electability1", "Electability2")]
df04[, c("NORMALIZED_IDEOLOGY1", "NORMALIZED_IDEOLOGY2", "Ideology", 
         "Ideology1", "Ideology2")]
```
 
 
## Clean Data (Part Three - Pivot Tibble)

```{r}
# 1. Pivot feeling thermometer ratings longer, since conditional logistic
# regressions require multiple rows per respondent (1 row per candidate).

my_cols <- c("ID", "VoteCandidate", "NORMALIZED_FT1", "NORMALIZED_FT2")
df <- df04[, my_cols]
colnames(df) <- c("ID", "VoteCandidate", my_candidate)

df <- df %>%
  pivot_longer(names_to = "Candidate", 
               values_to = "NORMALIZED_FT", 
               cols = -c(ID, VoteCandidate))
df_final <- df

# 2. Pivot viability ratings longer, since conditional logistic regressions
# require multiple rows per respondent (1 row per candidate).

my_cols <- c("ID", "NORMALIZED_VIABILITY1", "NORMALIZED_VIABILITY2")
df <- df04[, my_cols]
colnames(df) <- c("ID", my_candidate)

df <- df %>%
  pivot_longer(names_to = "Candidate", 
               values_to = "NORMALIZED_VIABILITY", 
               cols = -ID)

# Merge the pivoted viability ratings with the already-pivoted tibble.

df_final = merge(df_final, df, by=c("ID", "Candidate"))

# Convert VoteCandidate to 0, 1.

df_final$VoteCandidate <-  1 * (df_final$Candidate == df_final$VoteCandidate)

# 3. Pivot electability ratings longer, since conditional logistic regressions
# require multiple rows per respondent (1 row per candidate).

my_cols <- c("ID", "NORMALIZED_ELECTABILITY1", "NORMALIZED_ELECTABILITY2")
df <- df04[, my_cols]
colnames(df) <- c("ID", my_candidate)

df <- df %>%
  pivot_longer(names_to = "Candidate", 
               values_to = "NORMALIZED_ELECTABILITY", 
               cols = -ID)

# Merge pivoted electability ratings with the already-pivoted tibble.

df_final = merge(df_final, df, by = c("ID", "Candidate"))

# 4. Pivot ideology ratings longer, since conditional logistic regressions
# require multiple rows per respondent (1 row per candidate).

my_cols <- c("ID", "NORMALIZED_IDEOLOGY1", "NORMALIZED_IDEOLOGY2")
df <- df04[, my_cols]
colnames(df) <- c("ID", my_candidate)

df <- df %>%
  pivot_longer(names_to = "Candidate", 
               values_to = "NORMALIZED_IDEOLOGY", 
               cols = -ID)

# Merge pivoted ideology ratings with the already-pivoted tibble.

df_final = merge(df_final, df, by=c("ID", "Candidate"))
```


```{r}
# Create new columns using candidate names, assign 0 to all.

df_final[, sort(my_candidate)] <- 0

# Get index when intersection column name/value matches.

my_index <- cbind(seq_len(nrow(df_final)), 
                  match(df_final$Candidate, names(df_final)[-1]))

# Assign 1 to my_index cells.

df_final[-1][my_index] <- 1
```


## Write Cleaned Dataset

```{r}
df_final %>%
  drop_na() %>%
  write.dta("clean_data/df04_nh_d.dta")
```


##########


## Graphs of Candidate Viability and Electability 

```{r}

df_final %>%
  ggplot(aes(x = NORMALIZED_ELECTABILITY)) +
    geom_density() +
    facet_wrap(~ Candidate) +
    theme_bw() + 
    labs(
      title = "Candidate Electability",
      x = "Normalized Electability",
      y = "Density"
    ) +
  ggsave("/Users/ryan/Google Drive/2020_2021/Thesis/Figures/Figure2/naes04_nh_d_electability.bmp", width = 7.5, height = 4.5)

df_final %>%
  ggplot(aes(x = NORMALIZED_VIABILITY)) +
    geom_density() +
    facet_wrap(~ Candidate) +
    theme_bw() + 
    labs(
      title = "Candidate Viability",
      x = "Normalized Viability",
      y = "Density"
    ) +
  ggsave("/Users/ryan/Google Drive/2020_2021/Thesis/Figures/Figure2/naes04_nh_d_viability.bmp", width = 7.5, height = 4.5)
```


##########


## Create Voter Classification Table

```{r}
# Write new tibble that determines whether a respondent voted for the candidate
# that he or she viewed most strategically, or for the candidate that he or she
# viewed most sincerely, or both.

df_final_2 <- df_final %>%
  rowwise() %>%
  mutate(SINCERE = NORMALIZED_FT,
         STRATEGIC = (NORMALIZED_VIABILITY + NORMALIZED_ELECTABILITY) / 2) %>%
  select(ID, Candidate, VoteCandidate, SINCERE, STRATEGIC) %>%
  group_by(ID) %>%
  mutate(SINCERE_MAX1 = max(SINCERE),
         STRATEGIC_MAX1 = max(STRATEGIC)) %>%
  mutate(SINCERE_MAX2 = ifelse(SINCERE == SINCERE_MAX1, 1, 0),
         STRATEGIC_MAX2 = ifelse(STRATEGIC == STRATEGIC_MAX1, 1, 0)) %>%
  filter(VoteCandidate == 1) %>%
  drop_na()

df_final_2 %>%
  group_by(Candidate, SINCERE_MAX2, STRATEGIC_MAX2) %>%
  count() %>%
  group_by(Candidate) %>%
  mutate(percent = n / sum(n),
         df = "df04_nh_d") %>%
  write.csv("/Users/ryan/Google Drive/2020_2021/Thesis/Figures/Figure3/df04_nh_d_counts.csv")

df_final_2 %>%
  group_by(SINCERE_MAX2, STRATEGIC_MAX2) %>%
  count() %>%
  group_by() %>%
  mutate(percent = n / sum(n),
         df = "df04_nh_d") %>%
  write.csv("/Users/ryan/Google Drive/2020_2021/Thesis/Figures/Figure3/df04_nh_d_counts_aggregate.csv")
```


```{r include=FALSE}
rm(list = ls())
```

